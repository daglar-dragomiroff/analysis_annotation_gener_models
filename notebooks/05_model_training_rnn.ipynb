{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "import joblib\n",
    "\n",
    "# Загрузим обработанный датасет\n",
    "data_path = 'data/processed/'  # Путь к папке с .txt-книгами\n",
    "book_filenames = ['book1.txt', 'book2.txt', 'book3.txt']  # Пример списка файлов\n",
    "corpus = []\n",
    "for filename in book_filenames:\n",
    "    with open(data_path + filename, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        corpus.append(text)\n",
    "\n",
    "# Создадим токенизатор\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Преобразуем текст в последовательности чисел\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Подготовим данные для обучения\n",
    "max_sequence_length = max([len(seq) for seq in input_sequences])\n",
    "X = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
    "y = X[:, -1]\n",
    "X = X[:, :-1]\n",
    "\n",
    "# Создадим модель RNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Обучим модель\n",
    "model.fit(X, y, epochs=10, verbose=1)\n",
    "\n",
    "# Сохраним модель\n",
    "joblib.dump(model, 'models/rnn_model/rnn_model.h5')\n",
    "\n",
    "print(\"Модель RNN обучена и сохранена в 'models/rnn_model'.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
