{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import joblib\n",
    "\n",
    "# Загрузим обработанный датасет\n",
    "data_path = 'data/processed/'  # Путь к папке с .txt-книгами\n",
    "book_filenames = ['book1.txt', 'book2.txt', 'book3.txt']  # Пример списка файлов\n",
    "corpus = []\n",
    "for filename in book_filenames:\n",
    "    with open(data_path + filename, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        corpus.append(text)\n",
    "\n",
    "# Создадим токенизатор BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Преобразуем текст в токены\n",
    "input_ids = []\n",
    "for line in corpus:\n",
    "    encoded_text = tokenizer.encode(line, add_special_tokens=True)\n",
    "    input_ids.append(encoded_text)\n",
    "\n",
    "# Подготовим данные для обучения\n",
    "max_sequence_length = max([len(seq) for seq in input_ids])\n",
    "X = torch.tensor([seq + [0] * (max_sequence_length - len(seq)) for seq in input_ids])\n",
    "y = torch.tensor([0, 1, 0])  # Пример целевой переменной (0 - не интересно, 1 - интересно)\n",
    "\n",
    "# Создадим модель BERT для классификации\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Обучим модель\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "for epoch in range(5):\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_batch, labels = batch\n",
    "        outputs = model(input_batch, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Сохраним модель\n",
    "joblib.dump(model, 'models/bert_model/bert_model.pth')\n",
    "\n",
    "print(\"Модель BERT обучена и сохранена в 'models/bert_model'.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
