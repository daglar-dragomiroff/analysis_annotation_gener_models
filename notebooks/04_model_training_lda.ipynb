{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import joblib\n",
    "\n",
    "# Загрузим обработанный датасет\n",
    "data_path = 'data/processed/'  # Путь к папке с .txt-книгами\n",
    "book_filenames = ['book1.txt', 'book2.txt', 'book3.txt']  # Пример списка файлов\n",
    "corpus = []\n",
    "for filename in book_filenames:\n",
    "    with open(data_path + filename, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        corpus.append(text)\n",
    "\n",
    "# Создадим векторизатор Bag-of-Words\n",
    "vectorizer = CountVectorizer(max_features=5000)  # Можно настроить количество фичей\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Обучим модель LDA\n",
    "lda_model = LatentDirichletAllocation(n_components=5, random_state=42)  # Например, 5 тем\n",
    "lda_model.fit(X)\n",
    "\n",
    "# Сохраним модель\n",
    "joblib.dump(lda_model, 'models/lda_model/lda_model.pkl')\n",
    "\n",
    "print(\"Модель LDA обучена и сохранена в 'models/lda_model'.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
